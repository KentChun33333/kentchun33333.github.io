
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Sans+Pro:300,400,400i,700" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="https://kentchun33333.github.io/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="https://kentchun33333.github.io/theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="https://kentchun33333.github.io/theme/font-awesome/css/font-awesome.min.css">







<meta name="author" content="Kent Chiu" />
<meta name="description" content="Reimplement YOLO in Tensorflow with abstracting the deseign as the loss-layer." />
<meta name="keywords" content="tensorflow, implementation, object detection">

<meta property="og:site_name" content="Autumn Memo"/>
<meta property="og:title" content="Re-implement YOLO in Tensorflow"/>
<meta property="og:description" content="Reimplement YOLO in Tensorflow with abstracting the deseign as the loss-layer."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://kentchun33333.github.io/Re-implement YOLO in Tensorflow.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2017-12-30 20:00:00+01:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://kentchun33333.github.io/author/kent-chiu.html">
<meta property="article:section" content="AI Model Architectures"/>
<meta property="article:tag" content="tensorflow"/>
<meta property="article:tag" content="implementation"/>
<meta property="article:tag" content="object detection"/>
<meta property="og:image" content="https://scontent.fsin5-1.fna.fbcdn.net/v/t1.0-1/p720x720/96215235_3403513689663854_7453417891073884160_o.jpg?_nc_cat=106&_nc_sid=dbb9e7&_nc_ohc=FFyXABpAhHQAX9b-fUS&_nc_ht=scontent.fsin5-1.fna&_nc_tp=6&oh=3f722a46a66c21fadc044d92033c0590&oe=5EED0413">

  <title>Autumn Memo &ndash; Re-implement YOLO in Tensorflow</title>

</head>
<body>
  <aside>
    <div>
      <a href="https://kentchun33333.github.io">
        <img src="https://scontent.fsin5-1.fna.fbcdn.net/v/t1.0-1/p720x720/96215235_3403513689663854_7453417891073884160_o.jpg?_nc_cat=106&_nc_sid=dbb9e7&_nc_ohc=FFyXABpAhHQAX9b-fUS&_nc_ht=scontent.fsin5-1.fna&_nc_tp=6&oh=3f722a46a66c21fadc044d92033c0590&oe=5EED0413" alt="Kent Chiu" title="Kent Chiu">
      </a>
      <h1><a href="https://kentchun33333.github.io">Kent Chiu</a></h1>

<p>Algorithm Mind Space</p>

      <ul class="social">
        <li><a class="sc-linkedin" href="https://www.linkedin.com/in/kent-chiu-93b745a2?trk=hp-identity-photo" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        <li><a class="sc-github" href="https://github.com/KentChun33333" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-facebook" href="https://www.facebook.com/kent.chun" target="_blank"><i class="fa fa-facebook"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>

    <nav>
      <a href="https://kentchun33333.github.io">    Home
</a>

      <a href="/archives.html">Archives</a>
      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>


    </nav>

<article class="single">
  <header>
      
    <h1 id="Re-implement YOLO in Tensorflow">Re-implement YOLO in Tensorflow</h1>
    <p>
          Posted on Sat 30 December 2017 in <a href="https://kentchun33333.github.io/category/ai-model-architectures.html">AI Model Architectures</a>


    </p>
  </header>


  <div>
    <style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}





.rendered_html pre,




.rendered_html tr,
.rendered_html th,


.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,


.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] 
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css"> .highlight pre  .hll { background-color: #ffffcc }
 .highlight pre   { background: #f8f8f8; }
 .highlight pre  .c { color: #408080; font-style: italic } /* Comment */
 .highlight pre  .err { border: 1px solid #FF0000 } /* Error */
 .highlight pre  .k { color: #008000; font-weight: bold } /* Keyword */
 .highlight pre  .o { color: #666666 } /* Operator */
 .highlight pre  .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
 .highlight pre  .cm { color: #408080; font-style: italic } /* Comment.Multiline */
 .highlight pre  .cp { color: #BC7A00 } /* Comment.Preproc */
 .highlight pre  .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
 .highlight pre  .c1 { color: #408080; font-style: italic } /* Comment.Single */
 .highlight pre  .cs { color: #408080; font-style: italic } /* Comment.Special */
 .highlight pre  .gd { color: #A00000 } /* Generic.Deleted */
 .highlight pre  .ge { font-style: italic } /* Generic.Emph */
 .highlight pre  .gr { color: #FF0000 } /* Generic.Error */
 .highlight pre  .gh { color: #000080; font-weight: bold } /* Generic.Heading */
 .highlight pre  .gi { color: #00A000 } /* Generic.Inserted */
 .highlight pre  .go { color: #888888 } /* Generic.Output */
 .highlight pre  .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
 .highlight pre  .gs { font-weight: bold } /* Generic.Strong */
 .highlight pre  .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
 .highlight pre  .gt { color: #0044DD } /* Generic.Traceback */
 .highlight pre  .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
 .highlight pre  .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
 .highlight pre  .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
 .highlight pre  .kp { color: #008000 } /* Keyword.Pseudo */
 .highlight pre  .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
 .highlight pre  .kt { color: #B00040 } /* Keyword.Type */
 .highlight pre  .m { color: #666666 } /* Literal.Number */
 .highlight pre  .s { color: #BA2121 } /* Literal.String */
 .highlight pre  .na { color: #7D9029 } /* Name.Attribute */
 .highlight pre  .nb { color: #008000 } /* Name.Builtin */
 .highlight pre  .nc { color: #0000FF; font-weight: bold } /* Name.Class */
 .highlight pre  .no { color: #880000 } /* Name.Constant */
 .highlight pre  .nd { color: #AA22FF } /* Name.Decorator */
 .highlight pre  .ni { color: #999999; font-weight: bold } /* Name.Entity */
 .highlight pre  .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
 .highlight pre  .nf { color: #0000FF } /* Name.Function */
 .highlight pre  .nl { color: #A0A000 } /* Name.Label */
 .highlight pre  .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
 .highlight pre  .nt { color: #008000; font-weight: bold } /* Name.Tag */
 .highlight pre  .nv { color: #19177C } /* Name.Variable */
 .highlight pre  .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
 .highlight pre  .w { color: #bbbbbb } /* Text.Whitespace */
 .highlight pre  .mb { color: #666666 } /* Literal.Number.Bin */
 .highlight pre  .mf { color: #666666 } /* Literal.Number.Float */
 .highlight pre  .mh { color: #666666 } /* Literal.Number.Hex */
 .highlight pre  .mi { color: #666666 } /* Literal.Number.Integer */
 .highlight pre  .mo { color: #666666 } /* Literal.Number.Oct */
 .highlight pre  .sa { color: #BA2121 } /* Literal.String.Affix */
 .highlight pre  .sb { color: #BA2121 } /* Literal.String.Backtick */
 .highlight pre  .sc { color: #BA2121 } /* Literal.String.Char */
 .highlight pre  .dl { color: #BA2121 } /* Literal.String.Delimiter */
 .highlight pre  .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
 .highlight pre  .s2 { color: #BA2121 } /* Literal.String.Double */
 .highlight pre  .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
 .highlight pre  .sh { color: #BA2121 } /* Literal.String.Heredoc */
 .highlight pre  .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
 .highlight pre  .sx { color: #008000 } /* Literal.String.Other */
 .highlight pre  .sr { color: #BB6688 } /* Literal.String.Regex */
 .highlight pre  .s1 { color: #BA2121 } /* Literal.String.Single */
 .highlight pre  .ss { color: #19177C } /* Literal.String.Symbol */
 .highlight pre  .bp { color: #008000 } /* Name.Builtin.Pseudo */
 .highlight pre  .fm { color: #0000FF } /* Name.Function.Magic */
 .highlight pre  .vc { color: #19177C } /* Name.Variable.Class */
 .highlight pre  .vg { color: #19177C } /* Name.Variable.Global */
 .highlight pre  .vi { color: #19177C } /* Name.Variable.Instance */
 .highlight pre  .vm { color: #19177C } /* Name.Variable.Magic */
 .highlight pre  .il { color: #666666 } /* Literal.Number.Integer.Long */</style>
<style type="text/css">
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
</style>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Introduction">Introduction<a class="anchor-link" href="#Introduction">&#182;</a></h3><p>Recently <a href="https://arxiv.org/pdf/1506.02640v5.pdf">YOLO</a> and <a href="https://arxiv.org/pdf/1512.02325v2.pdf">SSD</a> have been seen as the most state-of-art algorithms on object detection in computer vision. They make a great progress on frame-per-second (FPS) with decent mean-average-perception (mAP).</p>
<p>One of their main strategy is actually to treat the detection problem as an regression. This ideal seems to be original from <a href="https://arxiv.org/pdf/1312.6229v4.pdf">OverFeat</a> and be strongly boosted by YOLO. Then SSD is a following work that combine the ideal with region-proposal-network from <a href="https://arxiv.org/pdf/1504.08083v2.pdf">FastRCNN</a> to make a trade-off on mAP vs FPS.</p>
<p>In this article, I am going to share how I reimplemet YOLO with tensorflow and what I have learned from YOLO strategy. My work is actually inspired by many other works. Please check these amazing works in reference section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<iframe width="100%" height="315"
src="https://www.youtube.com/embed/NM6lrxy0bxs" 
frameborder="0" 
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" 
allowfullscreen></iframe>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.-Key-Concept">1. Key Concept<a class="anchor-link" href="#1.-Key-Concept">&#182;</a></h3><ul>
<li><p>The key concept of YOLO-v1 could be divied into 2 parts.</p>
<ul>
<li>the design of encoded-output-tensor</li>
<li>the loss to make this encode-output-tensor trainable.</li>
</ul>
</li>
<li><p>The process of encoded tensor is kinds handcafted and is <strong>independent to</strong> the convnet itself. We could actually to think yolo-v1 is trying to let model to predict a better representation of BBOX output that better fitting the nature of object-detection. But since the output-tensor is kind of larger/sparse, so a coressponding customized loss are proprossed to solve it.</p>
</li>
</ul>
<h3 id="2-Design-of-Encoded-Output-Tensor">2 Design of Encoded-Output-Tensor<a class="anchor-link" href="#2-Design-of-Encoded-Output-Tensor">&#182;</a></h3><ul>
<li>The output tensor is composed by<ul>
<li>A designed grid system </li>
<li>bbox representation</li>
<li>probability of each object in each grid</li>
</ul>
</li>
</ul>
<h4 id="What-is-the-grid-system-in-yolo?">What is the grid system in yolo?<a class="anchor-link" href="#What-is-the-grid-system-in-yolo?">&#182;</a></h4><ul>
<li>YOLO divides the input image into an $S × S$ grid.Ex with 448 as image-width/height and S=7, we have (448/7, 448/7) = (64,64) in resolution. If the center of an object falls into a grid cell, the grid cell is responsible for detecting that object**. $C$ stands for how many class/object we are going to detect. </li>
</ul>
$$ \text{Grid Numbers} : S \times S \in \mathbb{R}^{1} $$<h4 id="What-is-BBox-representation?">What is BBox representation?<a class="anchor-link" href="#What-is-BBox-representation?">&#182;</a></h4><ul>
<li>In single grid, we predict $B$ BBox. Each BBox is representign a 5 dim tensor (x, y, wid, height, confidence-score). At first glance, it might be a little bit redundant for predicting multi-boxes in single grid.However, it is actually could enpower the capability of convnet, and by decent setting of selective loss function, it gives more generalibily to the convnet.</li>
</ul>
$$ \text{BBox Numbers} : B \in \mathbb{R}^{5} $$$$ B \equiv \{\ \text{x1, y1, wid, height, confidence score}\, \} $$<h4 id="What-is-Confidence-Score-in-BBox-representaton-?">What is Confidence-Score in BBox representaton ?<a class="anchor-link" href="#What-is-Confidence-Score-in-BBox-representaton-?">&#182;</a></h4><ul>
<li><p>confidence-score reflect how confident the model is that the box contains an object andalso how accurate it thinks the box is that it predicts. If <strong>no object</strong> exists in that cell, the <strong>confidence scores should be zero</strong>. Accordingly, we want the confidence score to equal <strong>the intersection over union (IOU)</strong> between the predicted box and the ground truth</p>
</li>
<li><p>$
\Pr ( \text{Confidence-Score} ) =
\begin{cases}
1,&amp; \text{ if there are objects } \\
0,&amp; \text{ if no object exiests }
\end{cases}</p>
</li>
<li>$</li>
</ul>
<h4 id="What-is-the-probability-of-each-object-in-each-grid?">What is the probability of each object in each grid?<a class="anchor-link" href="#What-is-the-probability-of-each-object-in-each-grid?">&#182;</a></h4><ul>
<li>They are actually simialr the tradicitonal one-hot-encoding output, the difference is we will have it in every grid.</li>
</ul>
$$ \text{Number of Objects } : C \in \mathbb{R}^{1}$$<h4 id="What-is-the-size-of-this-encoded-tensor?">What is the size of this encoded tensor?<a class="anchor-link" href="#What-is-the-size-of-this-encoded-tensor?">&#182;</a></h4><ul>
<li>Finally, the ouput of yolo-backbond is a encoded tensor with the size $S*S*(B*5+C)$, notice that much more sparse that triditional one-hot-vector encoder due to the tensor dimension is basically larger. We only predict one set of class probabilities per grid cell, regardless of the number of boxes B. </li>
</ul>
$$ \text{Input } : X \in \mathbb{R}^{448\times448\times3}$$$$ \text{Output } : Y \in \mathbb{R}^{S\times S\times (B\times5+C)}$$$$ Y = F_\text{cnn}(\text{ X }) $$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.-Specific-Loss-Design">3. Specific Loss Design<a class="anchor-link" href="#3.-Specific-Loss-Design">&#182;</a></h3><ul>
<li>The Loss could be decomposed to 3 part <ul>
<li>(1) sum-squared error BBox position and size information</li>
<li>(2) sum-squared error BBox object confidence-score</li>
<li>(3) sum-squared error of wich Class is in this grid.</li>
</ul>
</li>
</ul>
<h4 id="What-is-the-loss-of-BBox-position-and-size-information?">What is the loss of BBox position and size information?<a class="anchor-link" href="#What-is-the-loss-of-BBox-position-and-size-information?">&#182;</a></h4>$$
\lambda_{coord}\sum\limits_{i=0}^{S^2}{\sum\limits_{j=0}^{B}{1_{ij}^{obj}({(x_i -  \hat{x_i})^2 + (y_j + \hat{y_j})^2}})}
$$$$
+{\lambda_{coord}\sum\limits_{i=0}^{S^2}\sum\limits_{j=0}^{B}1_{ij}^{obj}((\sqrt{w_i} - \sqrt{\hat{w_i}})^2 +  (\sqrt{h_i} - \sqrt{\hat{h_i}})^2}
$$<h4 id="What-is-the-loss-sum-squared-error-BBox-object-confidence-score?">What is the loss sum-squared error BBox object confidence-score?<a class="anchor-link" href="#What-is-the-loss-sum-squared-error-BBox-object-confidence-score?">&#182;</a></h4>$$
+\sum\limits_{i=0}^{S^2}\sum\limits_{j=0}^{B}1_{ij}^{obj}(c_i - \hat{c_i})^2
$$$$
+\lambda_{noobj}\sum\limits_{i=0}^{S^2}\sum\limits_{j=0}^{B}1_{ij}^{noobj}(c_i - \hat{c_i})^2
$$<h4 id="What-is-the-loss-of-wich-Class-is-in-this-grid?">What is the loss of wich Class is in this grid?<a class="anchor-link" href="#What-is-the-loss-of-wich-Class-is-in-this-grid?">&#182;</a></h4>$$
+\sum\limits_{i =0}^{S^2}1_{i}^{obj}({\sum\limits_{c \in classes}(p_i(c)-\hat{p_i}(c))^2})
$$<h4 id="Why-there-are-some-special-coifficient?">Why there are some special coifficient?<a class="anchor-link" href="#Why-there-are-some-special-coifficient?">&#182;</a></h4><p>Original auther use <strong>sum-squared error</strong> because it is easy to optimize, however it does not perfectly align with our goal of maximizing average precision. It weights <strong>localization error</strong> equally with <strong>classification error</strong> which may not be ideal.</p>
<p>In (2) Orignal auther set <strong>λcoord = 5</strong> and <strong>λnoobj = .5.</strong> to increase the loss from bounding box coordinate predictions and decrease the loss from confi-dence predictions for boxes that don’t contain objects.</p>
<p>They want to remedy the model instability, which is caused by many grid cells do not contain any object. This pushes the <strong>“confidence” scores</strong> of those cells towards zero, often overpowering the gradient from cells that do contain objects.</p>
<p>Notice that: YOLO predicts <strong>multiple bounding boxes per grid cell.</strong> At training time we <strong>only want one bounding box predictor to be responsible for each object.</strong> We assign one predictor to be “responsible” for predicting an object based on which prediction has the <strong>highest current IOU with the ground truth.</strong>  This leads to specialization between the bounding box predictors. Each predictor gets better at predicting certain sizes, aspect ratios, or classes of object, improving overall recall.</p>
<h4 id="Overall-Math-Expression">Overall Math Expression<a class="anchor-link" href="#Overall-Math-Expression">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\lambda_{coord}\sum\limits_{i=0}^{S^2}{\sum\limits_{j=0}^{B}{1_{ij}^{obj} } ({(x_i -  \hat{x_i})^2 + (y_j + \hat{y_j})^2 + (\sqrt{w_i} - \sqrt{\hat{w_i}})^2 + (\sqrt{h_i} - \sqrt{\hat{h_i}})^2)}}
$$$$
+\sum\limits_{i=0}^{S^2}\sum\limits_{j=0}^{B}1_{ij}^{obj}(c_i - \hat{c_i})^2
$$$$
+\lambda_{noobj}\sum\limits_{i=0}^{S^2}\sum\limits_{j=0}^{B}1_{ij}^{noobj}(c_i - \hat{c_i})^2
$$$$
+\sum\limits_{i =0}^{S^2}1_{i}^{obj}({\sum\limits_{c \in classes}(p_i(c)-\hat{p_i}(c))^2})
$$<p>where $1^\text{obj}_{i}$ denotes if object appears in cell $i$ and $1^{obj}_{ij}$ denotes that the $j_{th}$ bounding box predictor in cell $i$ is “responsible” for that prediction.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.-YOLO-Loss-Layer-Implementation">4. YOLO Loss Layer Implementation<a class="anchor-link" href="#4.-YOLO-Loss-Layer-Implementation">&#182;</a></h3><p>The following are my partial implementation of yolo-v1.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>import numpy as np
from keras.engine import Layer
import tensorflow as tf 

# =============================================================================
# encode : (Ground Truth Box | Image ) -&gt; Ground Truth Y
# decode : Predict Tensor Y -&gt;
# the encode and decode are symmetric in logic
# =============================================================================


class YoloDetector(Layer):
    '''
    Description : 
    this class inherit keras-layer and providse the connectivity of tensorflow 
    this class implement the customize yolo-loss &amp; encode &amp; decode from [paper]
    (https://pjreddie.com/media/files/papers/yolo.pdf) for multi-object recog.  

    Usage: 
      loss = YoloDetector.loss(true_y, pred_y, batch_size=batch_size) # tf-stle slice must have same rank
      summary_op = get_summary_op(model, loss)
      ...
      _, lossN, summary_log = sess.run([train_step,loss,summary_op], feed_dict =
            {input_tensor : images_feed, true_y :labels_feed, K.learning_phase(): 0})

    '''
    def __init__(self, C=20, rImgW=448, rImgH=448, S=7, B=2, classMap=None):
        # C = number of class
        self.S = S
        self.B = B
        self.C = C
        self.W = rImgW
        self.H = rImgH
        self.iou_threshold=0.1
        if classMap:
            self.classMap = classMap
        else :
            self.classMap  =  ["aeroplane", "bicycle", "bird", "boat", "bottle", 
                           "bus", "car", "cat", "chair", "cow", "diningtable",
                           "dog", "horse", "motorbike", "person", "pottedplant",
                           "sheep", "sofa", "train","tvmonitor"]

    def set_class_map(self, mappingList):
        assert type(mappingList)==list ; assert len(mappingList) == self.C
        self.classMap=mappingList

    def encode(self, annotations):
        ''' annotations : nested list contained
        '''
        S, B, C, W, H = self.S, self.B, self.C, self.W, self.H

        # init
        classProb  = np.zeros([S, S, C   ])
        confidence = np.zeros([S, S, B   ])
        boxes      = np.zeros([S, S, B, 4])

        for classid, cX, cY, boxW, boxH in annotations:
            assert int(classid) &lt;= int(C-1)

            # Target the center grid
            gridX, gridY = W/S, H/S
            tarIdX, tarIdY = int(cX/gridX) , int(cY/gridY)    

            # assign the true value
            classProb[tarIdX, tarIdY, classid] = 1.0
            confidence[tarIdX, tarIdY, :      ] = 1.0    

            # x,y,w,h
            boxes[tarIdX, tarIdY, :, 0] = (cX/gridX) - int(cX/gridX)
            boxes[tarIdX, tarIdY, :, 1] = (cY/gridY) - int(cY/gridY)
            boxes[tarIdX, tarIdY, :, 2] = np.sqrt(boxW/W)
            boxes[tarIdX, tarIdY, :, 3] = np.sqrt(boxH/H)

        return np.concatenate([classProb.flatten(),confidence.flatten(),
                               boxes.flatten()])

    def traDim(self, pred, mode=3):
        ''' Dimension Transformation of Tensor '''
        S, B, C, W, H = self.S, self.B, self.C, self.W, self.H

        if mode == 3 :
            pred = np.array(pred)
            classProb  = np.reshape(pred[0:S*S*C]         , (S,S,C))
            confidence = np.reshape(pred[S*S*C: S*S*(C+B)], (S,S,B)) 
            boxes      = np.reshape(pred[S*S*(C+B):]      , (S,S,B,4))

        elif mode == 2 :
            classProb  = tf.reshape(pred[0:S*S*C]         , (S*S,C))
            confidence = tf.reshape(pred[S*S*C: S*S*(C+B)], (S*S,B)) 
            boxes      = tf.reshape(pred[S*S*(C+B):]      , (S*S,B,4))

        return classProb, confidence, boxes        

    def decode(self, prediction,threshold=8e-25 ,only_objectness=0):
        '''
        this part is modified from https://github.com/gliese581gg/YOLO_tensorflow
        '''
        S, B, C, W, H = self.S, self.B, self.C, self.W, self.H
        classProb ,confidence, boxes = self.traDim(prediction, mode =3)

        # offset (7,7,2) mask, retrieve from offset
        offset = np.transpose(np.reshape(np.array([np.arange(S)]*S*B),(B,S,S)),(1,2,0))
        boxes[:,:,:,1] += offset
        boxes[:,:,:,0] += np.transpose(offset,(1,0,2))
        boxes[:,:,:,0:2] = boxes[:,:,:,0:2] / float(S)

        # retrieve from sqrt
        boxes[:,:,:,2] = np.multiply(boxes[:,:,:,2],boxes[:,:,:,2])
        boxes[:,:,:,3] = np.multiply(boxes[:,:,:,3],boxes[:,:,:,3])

        # retrieve from normalization
        boxes[:,:,:,0] *= self.W ; boxes[:,:,:,1] *= self.H
        boxes[:,:,:,2] *= self.W ; boxes[:,:,:,3] *= self.H

        # Pr(class|Obj) * Pr(obj) = Evaluate Proba
        eProbs = np.zeros((S,S,B,C))
        for i in range(B):
            for j in range(C):
                eProbs[:,:,i,j]=np.multiply(classProb[:,:,j],confidence[:,:,i])

        # Filter
        filter_mat_probs = np.array(eProbs &gt;= threshold,dtype='bool')
        filter_mat_boxes = np.nonzero(filter_mat_probs)

        boxes_filtered = boxes[filter_mat_boxes[0],filter_mat_boxes[1],filter_mat_boxes[2]]
        probs_filtered = eProbs[filter_mat_probs]
        classes_num_filtered = np.argmax(filter_mat_probs,axis=3)[filter_mat_boxes[0],filter_mat_boxes[1],filter_mat_boxes[2]]

        argsort = np.array(np.argsort(probs_filtered))[::-1]
        boxes_filtered = boxes_filtered[argsort]
        probs_filtered = probs_filtered[argsort]
        classes_num_filtered = classes_num_filtered[argsort]

        # select the best pridect box with the ideal similar to nms
        # if there are 2 same probs, not likely, random pick one
        for i in range(len(boxes_filtered)):
            if probs_filtered[i] == 0 : continue
            for j in range(i+1,len(boxes_filtered)):
                if self.iou(boxes_filtered[i],boxes_filtered[j]) &gt; self.iou_threshold :
                    probs_filtered[j] = 0.0

        filter_iou = np.array(probs_filtered&gt;0.0,dtype='bool')
        boxes_filtered = boxes_filtered[filter_iou]
        probs_filtered = probs_filtered[filter_iou]
        classes_num_filtered = classes_num_filtered[filter_iou]

        result = []
        for i in range(len(boxes_filtered)):
            result.append([self.classMap[classes_num_filtered[i]],boxes_filtered[i][0],boxes_filtered[i][1],boxes_filtered[i][2],boxes_filtered[i][3],probs_filtered[i]])

        return result

    def loss(self, truY_, preY_, COORD=5. , NOOBJ=.5 , loss_=0 , batch_size=8):
        '''
        [description]
        - mini-batch optimization
        - the output of loss-function should &gt;= 0
        - use avg-loss of batch-size
        - max-gradient clip with loss max =1000.
        '''
        S, B, C, W, H = self.S, self.B, self.C, self.W, self.H

        for batch in range(batch_size):
            truY = truY_[batch,:]
            preY = preY_[batch,:]

            truCP ,truConf, truB = self.traDim(truY, mode=2)
            preCP ,preConf, preB = self.traDim(preY, mode=2)    

            #print truCP    

            # Select for responsible box which with max IOU
            iouT = self.iouTensor(truB,preB)           # iouT (7*7,2)
            iouT = tf.argmax(iouT, dimension=1) # (7*7)    

            # tf.cast(x, dtype, name=None)
            def slec_Box(raw , iouT):
                for i in range(S*S):
                    j = iouT[i]    

                    # flatten input 2D 
                    raw = tf.reshape(raw,[-1])     

                    # cast the idx to the right tyle
                    idx = tf.cast(tf.constant([0,1,2,3]), tf.int64)
                    idx_flattened = idx + (i*B*4+j)              
                    yield tf.gather(raw, idx_flattened)    

            def slec_conf(raw , iouT):
                for i in range(S*S):
                    j = iouT[i]    

                    # flatten input 2D 
                    raw = tf.reshape(raw,[-1])     

                    # cast the idx to the right tyle
                    idx = tf.cast(tf.constant([0]), tf.int64)
                    idx_flattened = idx + (i*B+j)              
                    yield tf.gather(raw, idx_flattened)
            # https://github.com/tensorflow/tensorflow/issues/206
            truB    = tf.pack ([ a for a in slec_Box (truB    , iouT)] )
            preB    = tf.pack ([ a for a in slec_Box (preB    , iouT)] )
            truConf = tf.pack ([ a for a in slec_conf(truConf , iouT)] )
            preConf = tf.pack ([ a for a in slec_conf(preConf , iouT)] )    

            # Obj or noobj is actually only depend on truth
            # truCP = (S*S,C)
            def max_tf(raw):
                for i in range(S*S):
                    tmp = raw[i,:]
                    tmp = tf.reduce_max(tmp)
                    yield tmp    

            objMask  = tf.pack([ a for a in max_tf(truCP) ])
            nobjMask = 1 - objMask    

            loss_ += tf.reduce_sum(tf.reduce_sum(tf.pow(truB-preB, 2), 1)   * objMask  ) * COORD 
            loss_ += tf.reduce_sum(tf.pow(truConf- preConf, 2)              * objMask  )
            loss_ += tf.reduce_sum(tf.pow(truConf- preConf, 2)              * nobjMask ) * NOOBJ
            loss_ += tf.reduce_sum(tf.reduce_sum(tf.pow(truCP- preCP, 2), 1)* objMask  )
        # clip gradient
        return max(float(loss_ / batch_size), 1000.)

    def boxArea(self, box):
        return box[:,:,2]*box[:,:,3]

    def iouTensor(self, box1, box2):
        S, B, C, W, H = self.S, self.B, self.C, self.W, self.H
        assert box1.get_shape() == box2.get_shape() == (S*S,B,4)

        minTop = tf.minimum(box1[:,:,0]+0.5*box1[:,:,2],
                      box2[:,:,0]+0.5*box2[:,:,2])
        maxBot = tf.maximum(box1[:,:,0]-0.5*box1[:,:,2],
                      box2[:,:,0]-0.5*box2[:,:,2])
        minR   = tf.minimum(box1[:,:,1]+0.5*box2[:,:,3],
                      box1[:,:,1]+0.5*box2[:,:,3])
        maxL   = tf.maximum(box1[:,:,1]-0.5*box2[:,:,3],
                      box1[:,:,1]-0.5*box2[:,:,3])
        # intersection

        #tf.clip_by_value(t, clip_value_min, clip_value_max, name=None)

        inters = tf.clip_by_value( minTop-maxBot, clip_value_min=0, clip_value_max=999)* \
                 tf.clip_by_value( minR-maxL    , clip_value_min=0, clip_value_max=999)
        noZero = 0.000000001 # Return IOU and avoid devide zero
        return inters/ (self.boxArea(box1)+ self.boxArea(box2)- inters+ noZero)

    def iou(self,box1,box2):
        tb = min(box1[0]+0.5*box1[2],
                 box2[0]+0.5*box2[2])-\
             max(box1[0]-0.5*box1[2],
                 box2[0]-0.5*box2[2])
        lr = min(box1[1]+0.5*box1[3],
                 box2[1]+0.5*box2[3])-\
             max(box1[1]-0.5*box1[3],
                 box2[1]-0.5*box2[3])
        if tb &lt; 0 or lr &lt; 0 : intersection = 0
        else : intersection =  tb*lr
        return intersection/ (box1[2]*box1[3] + box2[2]*box2[3] -intersection)

    def train(self, ):
        model = self.build()
        loss = self.loss
        model.compile(optimizer=RMSprop(lr=0.001), loss=loss, metrics=['accuracy'])</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Reference">Reference<a class="anchor-link" href="#Reference">&#182;</a></h3><ul>
<li><a href="https://github.com/gliese581gg/YOLO_tensorflow">https://github.com/gliese581gg/YOLO_tensorflow</a></li>
<li><a href="http://guanghan.info/blog/en/my-works/train-yolo/">http://guanghan.info/blog/en/my-works/train-yolo/</a></li>
<li><a href="https://github.com/thtrieu/yolotf">https://github.com/thtrieu/yolotf</a></li>
<li><a href="https://github.com/nilboy/tensorflow-yolo">https://github.com/nilboy/tensorflow-yolo</a></li>
<li><a href="https://github.com/gliese581gg/YOLO_tensorflow/blob/master/YOLO_tiny_tf.py">https://github.com/gliese581gg/YOLO_tensorflow/blob/master/YOLO_tiny_tf.py</a></li>
</ul>

</div>
</div>
</div>
 


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>

  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://kentchun33333.github.io/tag/tensorflow.html">tensorflow</a>
      <a href="https://kentchun33333.github.io/tag/implementation.html">implementation</a>
      <a href="https://kentchun33333.github.io/tag/object-detection.html">object detection</a>
    </p>
  </div>





<!-- Disqus -->
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'https-kentchun33333-github-io';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
        Please enable JavaScript to view comments.

</noscript>
<!-- End Disqus -->
</article>

    <footer>
<p>&copy;  </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Autumn Memo ",
  "url" : "https://kentchun33333.github.io",
  "image": "https://scontent.fsin5-1.fna.fbcdn.net/v/t1.0-1/p720x720/96215235_3403513689663854_7453417891073884160_o.jpg?_nc_cat=106&_nc_sid=dbb9e7&_nc_ohc=FFyXABpAhHQAX9b-fUS&_nc_ht=scontent.fsin5-1.fna&_nc_tp=6&oh=3f722a46a66c21fadc044d92033c0590&oe=5EED0413",
  "description": "Just Memos"
}
</script>

</body>
</html>